{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2. Исследование латентного пространства VAE. Исследование codebook VQ-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная лабораторная работа состоит из двух частей: исследование латентного пространства VAE и исследование codebook VQ-VAE.\n",
    "\n",
    "Предлагается обучить VAE и VQ-VAE на датасете fashionMNIST. Лабораторная работа должна быть выполнена на Pytorch.\n",
    "\n",
    "1. Что такое VAE? Зачем его придумали? Чем он отличается от обычного автокодировщика?\n",
    "2. Какие проблемы решает VQ-VAE? Чем он отличается от автокодировщика и вариационного автокодировщика?\n",
    "3. Что такое квантование в VQ-VAE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подгрузка импортов и датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((64, 64)),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Исследование латентного пространства VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части лабораторной работы предлагается обучить обычный VAE. С помощью инструментов снижения размерности (t-SNE или PCA) визуализируйте на плоскости внутреннее пространство VAE.\n",
    "Альтернативой станет выбор `dim_code=2` и визуализация результатов этого вариационного кодировщика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, dim_code):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.mu = ...\n",
    "        self.log_var = ...\n",
    "\n",
    "        self.decoder_input = ...\n",
    "\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3,  stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=3,  stride=2, output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        pass\n",
    "\n",
    "    def gaussian_sampler(self, mu, log_var):\n",
    "        pass\n",
    "\n",
    "    def decode(self, z):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAELoss(nn.Module):\n",
    "    def __init__(self, kl_weight=1, mse_weight=1):\n",
    "        pass\n",
    "    \n",
    "    def _kl_loss(self, mu, log_var):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, reconstruction, mu, log_var):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(model, dataloader, criterion, optimizer, epochs, device):\n",
    "    train_loss = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        train_epoch_loss = []\n",
    "        tqdm_iter = tqdm(dataloader)\n",
    "        for batch in tqdm_iter:\n",
    "            images, _ = batch\n",
    "            images = images.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(images)\n",
    "            reconstructed, mu, log_var = pred\n",
    "            loss = criterion(images, reconstructed, mu, log_var)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tqdm_iter.set_postfix(loss=f'{loss.item():.3f}')\n",
    "        train_epoch_loss.append(loss.item())\n",
    "        train_loss.append(np.mean(train_epoch_loss))\n",
    "        tqdm_iter.set_postfix(loss=f'{train_loss[-1]:.5f}')\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ...\n",
    "model = ...\n",
    "optimizer = ...\n",
    "epochs = ...\n",
    "device = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = train_autoencoder(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    epochs=epochs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualise_latent_space(\n",
    "        model,\n",
    "        # <your args here>\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Исследование codebook VQ-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуйте влияние гиперпараметров `embedding_dim, num_embeddings` на генерацию и сходимость VQ-VAE. В пределах каких значений генерация лучше? В пределах каких значений сходится кодировщик? От чего зависит диапазон значений для модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizerLoss(nn.Module):\n",
    "    def __init__(self, commitment_cost):\n",
    "        super().__init__()\n",
    "        self.commitment_cost = commitment_cost\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, z, quantized):\n",
    "        return self.mse(quantized.detach(), z) + self.commitment_cost * self.mse(quantized, z.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAELoss(nn.Module):\n",
    "    def __init__(self, commitment_cost=0.5):\n",
    "        super().__init__()\n",
    "        self.recon = nn.MSELoss()\n",
    "        self.quantizer = QuantizerLoss(commitment_cost)\n",
    "    \n",
    "    def forward(self, x, recon, z, quantized):\n",
    "        return self.recon(x, recon) + self.quantizer(z, quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_embeddings=10,\n",
    "            embedding_dim=128,\n",
    "            ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.quantizer = ...\n",
    "\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3,  stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=3,  stride=2, output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        pass\n",
    "\n",
    "    def decode(self, z):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование влияния гиперпараметров на результаты обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ...\n",
    "model = ...\n",
    "optimizer = ...\n",
    "epochs = ...\n",
    "device = ..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
